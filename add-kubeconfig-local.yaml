---
# =============================================================================
# Add Kubernetes Cluster to Local Kubeconfig
# Safely merges new cluster config without overwriting existing contexts
# =============================================================================

- name: Fetch and merge kubeconfig to local machine
  hosts: k8s_control_plane[0]
  become: false
  gather_facts: yes
  
  vars_prompt:
    - name: cluster_name
      prompt: "Enter a name for this cluster context (e.g., mtn-gh-qa, dev-cluster)"
      private: no
      
  tasks:
    - name: Validate cluster name
      assert:
        that:
          - cluster_name is defined
          - cluster_name != ""
          - cluster_name is match("^[a-zA-Z0-9][a-zA-Z0-9-]*$")
        fail_msg: "Cluster name must be alphanumeric with dashes (e.g., my-cluster-01)"
        success_msg: "Cluster name '{{ cluster_name }}' is valid"
      delegate_to: localhost
      run_once: true
      
    - name: Check if kubeconfig exists on control plane
      stat:
        path: /etc/kubernetes/admin.conf
      register: admin_conf
      become: true
      
    - name: Fail if kubeconfig not found
      fail:
        msg: "Kubernetes admin.conf not found. Is the cluster initialized?"
      when: not admin_conf.stat.exists
      
    - name: Get control plane endpoint
      set_fact:
        control_plane_ip: "{{ k8s_vip | default(ansible_default_ipv4.address) }}"
        cluster_name_fact: "{{ cluster_name }}"
        is_ha_cluster: "{{ k8s_vip is defined }}"
        
    - name: Display connection info
      debug:
        msg:
          - "Cluster name: {{ cluster_name }}"
          - "Control plane endpoint: {{ control_plane_ip }}"
          - "HA Mode: {{ 'Yes (using VIP)' if k8s_vip is defined else 'No (direct to node)' }}"
          - "Fetching kubeconfig from: {{ ansible_host }}"
          
    - name: Fetch kubeconfig from control plane
      slurp:
        src: /etc/kubernetes/admin.conf
      register: remote_kubeconfig
      become: true
      
    - name: Decode kubeconfig
      set_fact:
        kubeconfig_content: "{{ remote_kubeconfig.content | b64decode }}"

# =============================================================================
# Process and Merge on Local Machine
# =============================================================================
- name: Merge kubeconfig on local machine
  hosts: localhost
  connection: local
  gather_facts: yes
  
  vars:
    cluster_name: "{{ hostvars[groups['k8s_control_plane'][0]]['cluster_name_fact'] }}"
    control_plane_ip: "{{ hostvars[groups['k8s_control_plane'][0]]['control_plane_ip'] }}"
    kubeconfig_content: "{{ hostvars[groups['k8s_control_plane'][0]]['kubeconfig_content'] }}"
  
  tasks:
        
    - name: Create backup of local kubeconfig
      copy:
        src: ~/.kube/config
        dest: ~/.kube/config.backup.{{ ansible_date_time.epoch }}
        mode: '0600'
      when: lookup('file', '~/.kube/config', errors='ignore') is not none
      
    - name: Create .kube directory if it doesn't exist
      file:
        path: ~/.kube
        state: directory
        mode: '0700'
        
    - name: Save fetched kubeconfig to temporary file
      copy:
        content: "{{ kubeconfig_content }}"
        dest: /tmp/new-cluster-kubeconfig-original.yaml
        mode: '0600'
        
    - name: Check if local kubeconfig exists
      stat:
        path: ~/.kube/config
      register: local_kubeconfig
      
    - name: Prepare kubeconfig with proper naming (Python approach)
      shell: |
        python3 << 'PYTHON_EOF'
        import yaml
        import sys
        
        # Read the fetched kubeconfig
        with open('/tmp/new-cluster-kubeconfig-original.yaml', 'r') as f:
            config = yaml.safe_load(f)
        
        cluster_name = "{{ cluster_name }}"
        control_plane_ip = "{{ control_plane_ip }}"
        
        # Update cluster name and server
        if config.get('clusters'):
            config['clusters'][0]['name'] = cluster_name
            config['clusters'][0]['cluster']['server'] = f'https://{control_plane_ip}:6443'
        
        # Update user name
        if config.get('users'):
            config['users'][0]['name'] = f'{cluster_name}-admin'
        
        # Update context
        if config.get('contexts'):
            config['contexts'][0]['name'] = f'{cluster_name}-admin'
            config['contexts'][0]['context']['cluster'] = cluster_name
            config['contexts'][0]['context']['user'] = f'{cluster_name}-admin'
        
        # Update current-context
        config['current-context'] = f'{cluster_name}-admin'
        
        # Write modified config
        with open('/tmp/new-cluster-kubeconfig-renamed.yaml', 'w') as f:
            yaml.dump(config, f, default_flow_style=False)
        
        print(f"Successfully prepared kubeconfig for {cluster_name}")
        PYTHON_EOF
      register: prepare_result
      
    - name: Merge kubeconfigs using KUBECONFIG environment variable
      shell: |
        export KUBECONFIG=~/.kube/config:/tmp/new-cluster-kubeconfig-renamed.yaml
        kubectl config view --flatten > /tmp/merged-kubeconfig.yaml
        mv /tmp/merged-kubeconfig.yaml ~/.kube/config
        chmod 600 ~/.kube/config
      when: local_kubeconfig.stat.exists
      
    - name: Use new kubeconfig if no existing config (first cluster)
      copy:
        src: /tmp/new-cluster-kubeconfig-renamed.yaml
        dest: ~/.kube/config
        mode: '0600'
      when: not local_kubeconfig.stat.exists
      
    - name: Verify context was created
      shell: kubectl config get-contexts | grep -q '{{ cluster_name }}-admin'
      register: context_exists
      failed_when: false
      
    - name: Get previous context before switching
      shell: kubectl config current-context
      register: previous_context
      failed_when: false
      
    - name: Set new context as current
      command: kubectl config use-context {{ cluster_name }}-admin
      when: context_exists.rc == 0
      
    - name: Test connection with kubectl get nodes
      command: kubectl get nodes
      register: get_nodes_result
      failed_when: false
      retries: 3
      delay: 2
      until: get_nodes_result.rc == 0
      
    - name: Display nodes if successful
      debug:
        msg: "{{ get_nodes_result.stdout_lines }}"
      when: get_nodes_result.rc == 0
      
    - name: Rollback - Switch back to previous context
      command: kubectl config use-context {{ previous_context.stdout }}
      when: 
        - get_nodes_result.rc != 0
        - previous_context.stdout is defined
        - previous_context.stdout != ""
      ignore_errors: yes
      
    - name: Rollback - Delete cluster from kubeconfig
      command: kubectl config delete-cluster {{ cluster_name }}
      when: get_nodes_result.rc != 0
      ignore_errors: yes
      
    - name: Rollback - Delete user from kubeconfig
      command: kubectl config delete-user {{ cluster_name }}-admin
      when: get_nodes_result.rc != 0
      ignore_errors: yes
      
    - name: Rollback - Delete context from kubeconfig
      command: kubectl config delete-context {{ cluster_name }}-admin
      when: get_nodes_result.rc != 0
      ignore_errors: yes
      
    - name: Get all contexts after operations
      command: kubectl config get-contexts
      register: contexts_output
      
    - name: Clean up temporary files
      file:
        path: "{{ item }}"
        state: absent
      loop:
        - /tmp/new-cluster-kubeconfig-original.yaml
        - /tmp/new-cluster-kubeconfig-renamed.yaml
        - /tmp/merged-kubeconfig.yaml
      ignore_errors: yes
      
    - name: Display available contexts
      debug:
        msg: "{{ contexts_output.stdout_lines }}"
      
    - name: Display success message
      debug:
        msg:
          - " Kubeconfig successfully added and verified!"
          - ""
          - "Cluster: {{ cluster_name }}"
          - "Context: {{ cluster_name }}-admin"
          - "Server: https://{{ control_plane_ip }}:6443"
          - "Nodes: {{ get_nodes_result.stdout_lines | length - 1 }} node(s) found"
          - ""
          - " Commands:"
          - "  Switch context: kubectl config use-context {{ cluster_name }}-admin"
          - "  View contexts: kubectl config get-contexts"
          - "  Get nodes:     kubectl get nodes"
          - ""
          - " Backup saved: ~/.kube/config.backup.{{ ansible_date_time.epoch }}"
      when: get_nodes_result.rc == 0
          
    - name: Display failure message and rollback confirmation
      debug:
        msg:
          - " Failed to connect to cluster - Rolling back changes"
          - ""
          - "Error details:"
          - "{{ get_nodes_result.stderr_lines | default(['No error details available']) }}"
          - ""
          - "✓ Rolled back to previous context: {{ previous_context.stdout | default('N/A') }}"
          - "✓ Deleted cluster: {{ cluster_name }}"
          - "✓ Deleted user: {{ cluster_name }}-admin"
          - "✓ Deleted context: {{ cluster_name }}-admin"
          - ""
          - "Possible issues:"
          - "  - Firewall blocks port 6443 from your machine"
          - "  - VPN/network routing required"
          - "  - Control plane uses private IP not routable from here"
          - "  - Certificate or authentication problem"
          - ""
          - "Your kubeconfig has been restored to its previous state."
      when: get_nodes_result.rc != 0
      
    - name: Fail playbook if connection test failed
      fail:
        msg: "Failed to connect to cluster {{ cluster_name }}. All changes have been rolled back."
      when: get_nodes_result.rc != 0
